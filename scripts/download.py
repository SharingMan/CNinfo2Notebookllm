#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Download A-share stock reports from cninfo.com.cn
Stores PDFs in temporary directory, outputs file paths for upload
"""

import sys
import os
import json
import tempfile
import datetime
import time
import random
import httpx

# Stock database location
STOCKS_JSON = os.path.join(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "assets", "stocks.json"
)


class CnInfoDownloader:
    """Downloads reports from cninfo.com.cn"""

    def __init__(self):
        self.cookies = {
            "JSESSIONID": "9A110350B0056BE0C4FDD8A627EF2868",
            "insert_cookie": "37836164",
        }
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:110.0) Gecko/20100101 Firefox/110.0",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
            "X-Requested-With": "XMLHttpRequest",
            "Origin": "http://www.cninfo.com.cn",
            "Referer": "http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&lastPage=index",
        }
        self.timeout = httpx.Timeout(60.0)
        self.query_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
        self.market_to_stocks = self._load_stocks()

    def _load_stocks(self) -> dict:
        """Load stock database from JSON file"""
        if os.path.exists(STOCKS_JSON):
            with open(STOCKS_JSON, "r") as f:
                return json.load(f)
        return {}

    def find_stock(self, stock_input: str) -> tuple:
        """
        Find stock by code or name
        Returns: (stock_code, stock_info) or (None, None)
        """
        # Try as code first
        for market_stocks in self.market_to_stocks.values():
            if stock_input in market_stocks:
                return stock_input, market_stocks[stock_input]

        # Try as name
        for market_stocks in self.market_to_stocks.values():
            for code, info in market_stocks.items():
                if info.get("zwjc") == stock_input:
                    return code, info

        return None, None

    def _query_announcements(self, filter_params: dict) -> list:
        """Query cninfo API for announcements"""
        client = httpx.Client(
            headers=self.headers, cookies=self.cookies, timeout=self.timeout
        )

        # Get orgId for stock
        stock_code = filter_params["stock"][0]
        stock_info = None
        for market_stocks in self.market_to_stocks.values():
            if stock_code in market_stocks:
                stock_info = market_stocks[stock_code]
                break

        if not stock_info:
            return []

        payload = {
            "pageNum": 0,
            "pageSize": 30,
            "column": "szse",  # A-share market
            "tabName": "fulltext",
            "plate": "",
            "stock": f"{stock_code},{stock_info['orgId']}",
            "searchkey": filter_params.get("searchkey", ""),
            "secid": "",
            "category": ";".join(filter_params.get("category", [])),
            "trade": "",
            "seDate": filter_params.get("seDate", ""),
            "sortName": "",
            "sortType": "",
            "isHLtitle": False,
        }

        announcements = []
        has_more = True

        while has_more:
            payload["pageNum"] += 1
            try:
                resp = client.post(self.query_url, data=payload).json()
                has_more = resp.get("hasMore", False)
                if resp.get("announcements"):
                    announcements.extend(resp["announcements"])
            except Exception as e:
                print(f"Error querying API: {e}", file=sys.stderr)
                break

        return announcements

    def _download_pdf(self, announcement: dict, output_dir: str) -> str:
        """Download a single PDF file, returns file path"""
        client = httpx.Client(
            headers=self.headers, cookies=self.cookies, timeout=self.timeout
        )

        sec_code = announcement["secCode"]
        sec_name = announcement["secName"].replace("*", "s").replace("/", "-")
        title = announcement["announcementTitle"].replace("/", "-").replace("\\", "-")
        adjunct_url = announcement["adjunctUrl"]
        announcement_id = announcement["announcementId"]

        if announcement.get("adjunctType") != "PDF":
            return None

        filename = f"{sec_code}_{sec_name}_{title}_{announcement_id}.pdf"
        # Clean filename
        filename = "".join(c for c in filename if c.isalnum() or c in "._-")
        filepath = os.path.join(output_dir, filename)

        if not os.path.exists(filepath):
            try:
                print(f"Downloading: {title}")
                resp = client.get(f"http://static.cninfo.com.cn/{adjunct_url}")
                with open(filepath, "wb") as f:
                    f.write(resp.content)
                time.sleep(random.uniform(0.5, 1.5))  # Rate limiting
            except Exception as e:
                print(f"Download failed: {e}", file=sys.stderr)
                return None

        return filepath

    def _is_main_annual_report(self, title: str, year: int) -> bool:
        """Check if this is the main annual report (not summary/English)"""
        if f"{year}å¹´å¹´åº¦æŠ¥å‘Š" not in title and f"{year}å¹´å¹´æŠ¥" not in title:
            return False
        if "æ‘˜è¦" in title or "è‹±æ–‡" in title or "summary" in title.lower():
            return False
        if "æ›´æ­£" in title or "ä¿®è®¢" in title:
            return False
        return True

    def _is_main_periodic_report(self, title: str, report_type: str) -> bool:
        """Check if this is a main periodic report"""
        if "æ‘˜è¦" in title or "è‹±æ–‡" in title:
            return False
        if "æ›´æ­£" in title or "ä¿®è®¢" in title:
            return False

        if report_type == "semi":
            return "åŠå¹´åº¦æŠ¥å‘Š" in title or "ä¸­æœŸæŠ¥å‘Š" in title
        elif report_type == "q1":
            return "ä¸€å­£åº¦" in title or "ç¬¬ä¸€å­£åº¦" in title
        elif report_type == "q3":
            return "ä¸‰å­£åº¦" in title or "ç¬¬ä¸‰å­£åº¦" in title

        return False

    def download_annual_reports(
        self, stock_code: str, years: list, output_dir: str
    ) -> list:
        """Download annual reports for specified years"""
        downloaded = []

        for year in years:
            # Annual reports are published in the following year (March-April)
            search_start = f"{year + 1}-01-01"
            search_end = f"{year + 1}-06-30"

            filter_params = {
                "stock": [stock_code],
                "category": ["category_ndbg_szsh"],  # Annual reports
                "searchkey": f"{year}å¹´å¹´åº¦æŠ¥å‘Š",
                "seDate": f"{search_start}~{search_end}",
            }

            announcements = self._query_announcements(filter_params)

            for ann in announcements:
                if self._is_main_annual_report(ann["announcementTitle"], year):
                    filepath = self._download_pdf(ann, output_dir)
                    if filepath:
                        downloaded.append(filepath)
                        print(f"âœ… Downloaded: {year} Annual Report")
                    break  # Only get one per year

        return downloaded

    def download_periodic_reports(
        self, stock_code: str, year: int, output_dir: str
    ) -> list:
        """Download Q1, semi-annual, Q3 reports for current year"""
        downloaded = []

        report_configs = [
            (
                "q1",
                "category_yjdbg_szsh",
                "ä¸€å­£åº¦æŠ¥å‘Š",
                f"{year}-04-01",
                f"{year}-05-31",
            ),
            (
                "semi",
                "category_bndbg_szsh",
                "åŠå¹´åº¦æŠ¥å‘Š",
                f"{year}-08-01",
                f"{year}-09-30",
            ),
            (
                "q3",
                "category_sjdbg_szsh",
                "ä¸‰å­£åº¦æŠ¥å‘Š",
                f"{year}-10-01",
                f"{year}-11-30",
            ),
        ]

        for report_type, category, search_term, start_date, end_date in report_configs:
            filter_params = {
                "stock": [stock_code],
                "category": [category],
                "searchkey": search_term,
                "seDate": f"{start_date}~{end_date}",
            }

            announcements = self._query_announcements(filter_params)

            for ann in announcements:
                if self._is_main_periodic_report(ann["announcementTitle"], report_type):
                    filepath = self._download_pdf(ann, output_dir)
                    if filepath:
                        downloaded.append(filepath)
                        print(f"âœ… Downloaded: {year} {search_term}")
                    break

        return downloaded


def main():
    """Main entry point - downloads reports and prints file paths"""
    if len(sys.argv) < 2:
        print("Usage: python download.py <stock_code_or_name> [output_dir]")
        print("Example: python download.py 600350")
        print("Example: python download.py å±±ä¸œé«˜é€Ÿ")
        sys.exit(1)

    stock_input = sys.argv[1]
    output_dir = (
        sys.argv[2] if len(sys.argv) > 2 else tempfile.mkdtemp(prefix="cninfo_reports_")
    )

    downloader = CnInfoDownloader()

    # Find stock
    stock_code, stock_info = downloader.find_stock(stock_input)
    if not stock_code:
        print(f"âŒ Stock not found: {stock_input}", file=sys.stderr)
        sys.exit(1)

    stock_name = stock_info.get("zwjc", stock_code)
    print(f"ğŸ“Š Found stock: {stock_code} ({stock_name})")
    print(f"ğŸ“ Output directory: {output_dir}")

    # Calculate years
    current_year = datetime.datetime.now().year
    annual_years = list(range(current_year - 5, current_year))  # Last 5 years

    print(f"\nğŸ“¥ Downloading annual reports for: {annual_years}")
    annual_files = downloader.download_annual_reports(
        stock_code, annual_years, output_dir
    )

    # Try current year for periodic reports, fallback to previous year
    print(f"\nğŸ“¥ Downloading periodic reports (Q1, semi-annual, Q3)...")
    periodic_files = downloader.download_periodic_reports(
        stock_code, current_year, output_dir
    )

    # If no periodic reports found in current year, try previous year
    if not periodic_files:
        print(f"   No {current_year} reports yet, trying {current_year - 1}...")
        periodic_files = downloader.download_periodic_reports(
            stock_code, current_year - 1, output_dir
        )
    # If some but not all, also check previous year for missing ones
    elif len(periodic_files) < 3:
        print(f"   Checking {current_year - 1} for additional reports...")
        prev_year_files = downloader.download_periodic_reports(
            stock_code, current_year - 1, output_dir
        )
        periodic_files.extend(prev_year_files)

    all_files = annual_files + periodic_files

    print(f"\n{'=' * 50}")
    print(f"âœ… Downloaded {len(all_files)} reports")
    print(f"ğŸ“ Location: {output_dir}")
    print(f"\nğŸ“„ Files:")
    for f in all_files:
        print(f"  {os.path.basename(f)}")

    # Output JSON for easy parsing by upload script
    result = {
        "stock_code": stock_code,
        "stock_name": stock_name,
        "output_dir": output_dir,
        "files": all_files,
    }

    # Write result to stdout marker for parsing
    print(f"\n---JSON_OUTPUT---")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
